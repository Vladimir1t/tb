"""
–î–≤–∏–∂–æ–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã
–†–µ–∞–ª–∏–∑—É–µ—Ç 3-—ç—Ç–∞–ø–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É:
1. –°–±–æ—Ä —Å–∏–≥–Ω–∞–ª–æ–≤ (–ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)
2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (~1000)
3. –õ–µ–≥–∫–∏–π —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥ (—Ç–æ–ø-100)
"""
import sqlite3
import json
import math
import time
from typing import List, Dict, Set, Tuple, Optional
from collections import Counter, defaultdict, OrderedDict
from datetime import datetime, timedelta
import threading

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –º–æ–¥—É–ª–µ–π
from routers.projects import (
    search_index, 
    project_data_cache,
    normalize_and_stem,
    expand_query_with_synonyms,
    calculate_cosine_similarity,
    stem_word
)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –∫—ç—à–∏ —Å LRU
_USER_PROFILE_CACHE_MAX_SIZE = 10000  # –ú–∞–∫—Å–∏–º—É–º 10–ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ –∫—ç—à–µ
_user_profile_cache = OrderedDict()  # OrderedDict –¥–ª—è LRU (Least Recently Used)
_user_profile_cache_lock = threading.Lock()
_USER_PROFILE_TTL = 86400  # 24 —á–∞—Å–∞ (–±—ã–ª–æ 5 –º–∏–Ω—É—Ç)

_inverted_index = {}  # {token: set(project_ids)}
_inverted_index_lock = threading.Lock()
_inverted_index_built = False

# –í–µ—Å–∞ –¥–ª—è —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è (–º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å)
WEIGHTS = {
    'sim_content': 1.0,      # –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ —Å –ø—Ä–æ—Ñ–∏–ª–µ–º
    'theme_match': 2.0,      # –¢–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Ç–µ–º
    'popularity': 0.3,       # –ü–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å (subscribers/likes)
    'recency_boost': 0.5,    # –ü–æ—Ö–æ–∂–µ—Å—Ç—å –Ω–∞ –Ω–µ–¥–∞–≤–Ω–∏–µ –∫–ª–∏–∫–∏
    'seen_penalty': -2.0,    # –®—Ç—Ä–∞—Ñ –∑–∞ –Ω–µ–¥–∞–≤–Ω–æ –ø–æ–∫–∞–∑–∞–Ω–Ω–æ–µ
}

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
CANDIDATE_LIMITS = {
    'from_preferences': 400,
    'similar_to_clicks': 300,
    'popular_in_themes': 200,
    'exploration': 100,
}

def build_inverted_index():
    """–°—Ç—Ä–æ–∏—Ç –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å token -> set(project_ids)"""
    global _inverted_index, _inverted_index_built
    
    with _inverted_index_lock:
        if _inverted_index_built:
            return
        
        print("üî® –°—Ç—Ä–æ–∏–º –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π...")
        _inverted_index = defaultdict(set)
        
        for project_id, project_data in search_index.items():
            tokens = project_data.get('all_tokens', set())
            for token in tokens:
                _inverted_index[token].add(project_id)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –æ–±—ã—á–Ω—ã–π dict –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
        _inverted_index = dict(_inverted_index)
        _inverted_index_built = True
        print(f"‚úÖ –ò–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å –ø–æ—Å—Ç—Ä–æ–µ–Ω: {len(_inverted_index)} —Ç–æ–∫–µ–Ω–æ–≤")


def get_user_profile(user_id: int, conn: sqlite3.Connection) -> Dict:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∏–ª–∏ —Å—Ç—Ä–æ–∏—Ç –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å LRU –∫—ç—à–µ–º
    –ü—Ä–æ—Ñ–∏–ª—å —Å–æ–¥–µ—Ä–∂–∏—Ç:
    - preferences_tokens: —Ç–æ–∫–µ–Ω—ã –∏–∑ –æ–ø—Ä–æ—Å–∞ (main_topics, sub_topics)
    - click_tokens: —Ç–æ–∫–µ–Ω—ã –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∫–ª–∏–∫–æ–≤
    - tf_vector: —É—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã–π TF-–≤–µ–∫—Ç–æ—Ä
    - recent_project_ids: –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç—ã
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
    with _user_profile_cache_lock:
        if user_id in _user_profile_cache:
            profile, timestamp = _user_profile_cache[user_id]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º TTL
            if time.time() - timestamp < _USER_PROFILE_TTL:
                # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –≤ –∫–æ–Ω–µ—Ü OrderedDict (–æ–±–Ω–æ–≤–ª—è–µ–º "recency")
                _user_profile_cache.move_to_end(user_id)
                return profile
            else:
                # TTL –∏—Å—Ç–µ–∫ - —É–¥–∞–ª—è–µ–º
                del _user_profile_cache[user_id]
    
    # –°—Ç—Ä–æ–∏–º –ø—Ä–æ—Ñ–∏–ª—å
    profile = {
        'preferences_tokens': set(),
        'click_tokens': set(),
        'tf_vector': {},
        'recent_project_ids': [],
        'themes': set(),
    }
    
    cursor = conn.cursor()
    
    # 1. –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –∏–∑ –æ–ø—Ä–æ—Å–∞
    cursor.execute("SELECT preferences FROM users WHERE id = ?", (user_id,))
    row = cursor.fetchone()
    
    if row and row[0]:
        try:
            prefs = json.loads(row[0])
            main_topics = prefs.get('main_topics', [])
            sub_topics = prefs.get('sub_topics', [])
            
            # –†–∞—Å—à–∏—Ä—è–µ–º —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏ –∏ —Å—Ç–µ–º–º–∏–Ω–≥–æ–º
            all_topics = main_topics + sub_topics
            for topic in all_topics:
                # –î–æ–±–∞–≤–ª—è–µ–º —Å–∞–º —Ç–æ–ø–∏–∫
                profile['themes'].add(topic.lower())
                
                # –†–∞—Å—à–∏—Ä—è–µ–º —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏
                expanded = expand_query_with_synonyms(topic)
                profile['preferences_tokens'].update(expanded)
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–µ–º–º—ã
                words = topic.lower().split()
                for word in words:
                    stemmed = stem_word(word)
                    if stemmed:
                        profile['preferences_tokens'].add(stemmed)
        except:
            pass
    
    # 2. –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∫–ª–∏–∫–∏/–ª–∞–π–∫–∏ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 1000)
    cursor.execute('''
        SELECT DISTINCT project_id 
        FROM interactions 
        WHERE user_id = ? AND event_type IN ('click', 'like')
        ORDER BY ts DESC 
        LIMIT 1000
    ''', (user_id,))
    
    clicked_projects = [row[0] for row in cursor.fetchall()]
    profile['recent_project_ids'] = clicked_projects[:100]  # –•—Ä–∞–Ω–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 100 –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
    
    # –°–æ–±–∏—Ä–∞–µ–º —Ç–æ–∫–µ–Ω—ã –∏–∑ –∫–ª–∏–∫–Ω—É—Ç—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤
    tf_vectors = []
    for project_id in clicked_projects:
        if project_id in search_index:
            project_tokens = search_index[project_id].get('all_tokens', set())
            profile['click_tokens'].update(project_tokens)
            
            # –°–æ–±–∏—Ä–∞–µ–º TF-–≤–µ–∫—Ç–æ—Ä—ã –¥–ª—è —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è
            tf_vectors.append(search_index[project_id].get('tf', {}))
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–º—ã –ø—Ä–æ–µ–∫—Ç–æ–≤
            if project_id in project_data_cache:
                theme = project_data_cache[project_id].get('theme', '')
                if theme:
                    profile['themes'].add(theme.lower())
    
    # 3. –£—Å—Ä–µ–¥–Ω—è–µ–º TF-–≤–µ–∫—Ç–æ—Ä—ã
    if tf_vectors:
        all_terms = set()
        for tf in tf_vectors:
            all_terms.update(tf.keys())
        
        for term in all_terms:
            values = [tf.get(term, 0) for tf in tf_vectors]
            profile['tf_vector'][term] = sum(values) / len(tf_vectors)
    else:
        # –ï—Å–ª–∏ –Ω–µ—Ç –∫–ª–∏–∫–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ preferences
        for token in profile['preferences_tokens']:
            profile['tf_vector'][token] = 1.0 / max(len(profile['preferences_tokens']), 1)
    
    # –ö—ç—à–∏—Ä—É–µ–º –ø—Ä–æ—Ñ–∏–ª—å —Å LRU —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º
    with _user_profile_cache_lock:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞
        if len(_user_profile_cache) >= _USER_PROFILE_CACHE_MAX_SIZE:
            # –£–¥–∞–ª—è–µ–º —Å–∞–º—ã–π —Å—Ç–∞—Ä—ã–π (–ø–µ—Ä–≤—ã–π –≤ OrderedDict)
            oldest_user_id = next(iter(_user_profile_cache))
            del _user_profile_cache[oldest_user_id]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–Ω–µ—Ü (—Å–∞–º—ã–π —Å–≤–µ–∂–∏–π)
        _user_profile_cache[user_id] = (profile, time.time())
    
    return profile


def generate_candidates(
    user_profile: Dict, 
    user_id: int,
    conn: sqlite3.Connection,
    content_type: Optional[str] = None
) -> List[int]:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç ~1000 –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    """
    if not _inverted_index_built:
        build_inverted_index()
    
    candidates = set()
    cursor = conn.cursor()
    
    # –ü–æ–ª—É—á–∞–µ–º –Ω–µ–¥–∞–≤–Ω–æ –ø–æ–∫–∞–∑–∞–Ω–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç—ã –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è
    cursor.execute('''
        SELECT DISTINCT project_id 
        FROM interactions 
        WHERE user_id = ? AND event_type IN ('impression', 'click', 'not_interested')
        AND ts > datetime('now', '-7 days')
    ''', (user_id,))
    recently_seen = set(row[0] for row in cursor.fetchall())
    
    # 1. –ö–∞–Ω–¥–∏–¥–∞—Ç—ã –ø–æ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è–º (–æ–ø—Ä–æ—Å + —Å–∏–Ω–æ–Ω–∏–º—ã)
    pref_tokens = user_profile['preferences_tokens']
    pref_candidates = set()
    
    for token in pref_tokens:
        if token in _inverted_index:
            pref_candidates.update(_inverted_index[token])
            if len(pref_candidates) >= CANDIDATE_LIMITS['from_preferences']:
                break
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ç–∏–ø—É
    if content_type and content_type != 'all':
        type_map = {'channels': 'channel', 'bots': 'bot', 'apps': 'mini_app'}
        target_type = type_map.get(content_type, content_type)
        pref_candidates = {
            pid for pid in pref_candidates 
            if project_data_cache.get(pid, {}).get('type') == target_type
        }
    
    candidates.update(list(pref_candidates)[:CANDIDATE_LIMITS['from_preferences']])
    
    # 2. –ü–æ—Ö–æ–∂–∏–µ –Ω–∞ –Ω–µ–¥–∞–≤–Ω–∏–µ –∫–ª–∏–∫–∏
    recent_clicks = user_profile['recent_project_ids'][:5]
    similar_candidates = set()
    
    for clicked_id in recent_clicks:
        if clicked_id in search_index:
            clicked_tokens = search_index[clicked_id].get('all_tokens', set())
            
            # –ù–∞—Ö–æ–¥–∏–º –ø—Ä–æ–µ–∫—Ç—ã —Å –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ–º —Ç–æ–∫–µ–Ω–æ–≤
            for token in list(clicked_tokens)[:50]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
                if token in _inverted_index:
                    similar_candidates.update(_inverted_index[token])
                    if len(similar_candidates) >= CANDIDATE_LIMITS['similar_to_clicks']:
                        break
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ç–∏–ø—É
    if content_type and content_type != 'all':
        similar_candidates = {
            pid for pid in similar_candidates 
            if project_data_cache.get(pid, {}).get('type') == target_type
        }
    
    candidates.update(list(similar_candidates)[:CANDIDATE_LIMITS['similar_to_clicks']])
    
    # 3. –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –≤ —Ç–µ–º–∞—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    user_themes = user_profile['themes']
    popular_candidates = []
    
    if user_themes:
        # –ò—â–µ–º –ø—Ä–æ–µ–∫—Ç—ã —Å —Å–æ–≤–ø–∞–¥–∞—é—â–∏–º–∏ —Ç–µ–º–∞–º–∏, —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏
        for project_id, project_info in project_data_cache.items():
            project_theme = project_info.get('theme', '').lower()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ç–µ–º
            theme_match = any(theme in project_theme for theme in user_themes)
            if theme_match:
                # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ç–∏–ø—É
                if content_type and content_type != 'all':
                    if project_info.get('type') != target_type:
                        continue
                
                subscribers = project_info.get('subscribers', 0)
                likes = project_info.get('likes', 0)
                popularity = subscribers + likes * 10
                popular_candidates.append((project_id, popularity))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏
        popular_candidates.sort(key=lambda x: x[1], reverse=True)
        candidates.update([pid for pid, _ in popular_candidates[:CANDIDATE_LIMITS['popular_in_themes']]])
    
    # 4. Exploration: —Å–ª—É—á–∞–π–Ω—ã–µ –∏–∑ –±–ª–∏–∑–∫–∏—Ö —Ç–µ–º
    if len(candidates) < 800:
        all_project_ids = list(project_data_cache.keys())
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ç–∏–ø—É
        if content_type and content_type != 'all':
            all_project_ids = [
                pid for pid in all_project_ids 
                if project_data_cache.get(pid, {}).get('type') == target_type
            ]
        
        import random
        exploration_pool = [pid for pid in all_project_ids if pid not in candidates]
        exploration_sample = random.sample(
            exploration_pool, 
            min(CANDIDATE_LIMITS['exploration'], len(exploration_pool))
        )
        candidates.update(exploration_sample)
    
    # –£–±–∏—Ä–∞–µ–º –Ω–µ–¥–∞–≤–Ω–æ –ø–æ–∫–∞–∑–∞–Ω–Ω—ã–µ
    candidates = candidates - recently_seen
    
    # –£–±–∏—Ä–∞–µ–º –Ω–µ–¥–∞–≤–Ω–∏–µ –∫–ª–∏–∫–∏ (—á—Ç–æ–±—ã –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω–æ)
    candidates = candidates - set(user_profile['recent_project_ids'])
    
    return list(candidates)


def rerank_candidates(
    candidates: List[int],
    user_profile: Dict,
    user_id: int,
    conn: sqlite3.Connection
) -> List[Tuple[int, float, str]]:
    """
    –õ–µ–≥–∫–∏–π —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —Å –≤–µ—Å–∞–º–∏
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ (project_id, score, reason)
    """
    cursor = conn.cursor()
    
    # –ü–æ–ª—É—á–∞–µ–º –Ω–µ–¥–∞–≤–Ω–æ –ø–æ–∫–∞–∑–∞–Ω–Ω—ã–µ –¥–ª—è —à—Ç—Ä–∞—Ñ–∞
    cursor.execute('''
        SELECT project_id, MAX(ts) as last_seen
        FROM interactions 
        WHERE user_id = ? AND event_type = 'impression'
        AND ts > datetime('now', '-3 days')
        GROUP BY project_id
    ''', (user_id,))
    
    recently_shown = {}
    for row in cursor.fetchall():
        project_id, last_seen_str = row
        try:
            last_seen = datetime.fromisoformat(last_seen_str)
            hours_ago = (datetime.now() - last_seen).total_seconds() / 3600
            recently_shown[project_id] = hours_ago
        except:
            pass
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏ (min-max)
    all_subscribers = [
        project_data_cache.get(pid, {}).get('subscribers', 0) 
        for pid in candidates
    ]
    max_subs = max(all_subscribers) if all_subscribers else 1
    min_subs = min(all_subscribers) if all_subscribers else 0
    subs_range = max_subs - min_subs if max_subs > min_subs else 1
    
    scored_candidates = []
    user_tf = user_profile['tf_vector']
    recent_click_ids = set(user_profile['recent_project_ids'][:5])
    user_themes = user_profile['themes']
    
    for project_id in candidates:
        if project_id not in search_index or project_id not in project_data_cache:
            continue
        
        project_index = search_index[project_id]
        project_info = project_data_cache[project_id]
        
        # 1. –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ —Å –ø—Ä–æ—Ñ–∏–ª–µ–º
        project_tf = project_index.get('tf', {})
        sim_content = calculate_cosine_similarity(user_tf, project_tf)
        
        # 2. –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ç–µ–º
        project_theme = project_info.get('theme', '').lower()
        project_name = project_info.get('name', '').lower()
        
        theme_match_score = 0
        matched_themes = []
        for theme in user_themes:
            if theme in project_theme:
                theme_match_score += 1.0
                matched_themes.append(theme)
            elif theme in project_name:
                theme_match_score += 0.5
                matched_themes.append(theme)
        
        # 3. –ü–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è)
        subscribers = project_info.get('subscribers', 0)
        likes = project_info.get('likes', 0)
        popularity_raw = subscribers + likes * 10
        popularity_norm = (subscribers - min_subs) / subs_range if subs_range > 0 else 0
        
        # 4. Recency boost (–ø–æ—Ö–æ–∂–µ—Å—Ç—å –Ω–∞ –Ω–µ–¥–∞–≤–Ω–∏–µ –∫–ª–∏–∫–∏)
        recency_boost = 0
        if recent_click_ids:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤ —Å –Ω–µ–¥–∞–≤–Ω–∏–º–∏ –∫–ª–∏–∫–∞–º–∏
            project_tokens = project_index.get('all_tokens', set())
            for clicked_id in recent_click_ids:
                if clicked_id in search_index:
                    clicked_tokens = search_index[clicked_id].get('all_tokens', set())
                    overlap = len(project_tokens & clicked_tokens)
                    if overlap > 5:
                        recency_boost += 0.5
        
        # 5. –®—Ç—Ä–∞—Ñ –∑–∞ –Ω–µ–¥–∞–≤–Ω–æ –ø–æ–∫–∞–∑–∞–Ω–Ω–æ–µ (–¥–æ 48 —á–∞—Å–æ–≤)
        seen_penalty = 0
        if project_id in recently_shown:
            hours_ago = recently_shown[project_id]
            if hours_ago < 48:  # –®—Ç—Ä–∞—Ñ –¥–µ–π—Å—Ç–≤—É–µ—Ç –¥–æ 48 —á–∞—Å–æ–≤
                seen_penalty = 1.0 - (hours_ago / 48)  # –ß–µ–º —Å–≤–µ–∂–µ–µ, —Ç–µ–º –±–æ–ª—å—à–µ —à—Ç—Ä–∞—Ñ
        
        # –ò—Ç–æ–≥–æ–≤—ã–π —Å–∫–æ—Ä
        score = (
            WEIGHTS['sim_content'] * sim_content +
            WEIGHTS['theme_match'] * theme_match_score +
            WEIGHTS['popularity'] * popularity_norm +
            WEIGHTS['recency_boost'] * recency_boost +
            WEIGHTS['seen_penalty'] * seen_penalty
        )
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–∏—á–∏–Ω—É —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        reason_parts = []
        if matched_themes:
            reason_parts.append(f"–¢–µ–º—ã: {', '.join(matched_themes[:2])}")
        if recency_boost > 0:
            reason_parts.append("–ü–æ—Ö–æ–∂–µ –Ω–∞ –≤–∞—à–∏ –∫–ª–∏–∫–∏")
        if popularity_raw > 10000:
            reason_parts.append("–ü–æ–ø—É–ª—è—Ä–Ω–æ–µ")
        
        reason = " ‚Ä¢ ".join(reason_parts) if reason_parts else "–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º"
        
        scored_candidates.append((project_id, score, reason))
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å–∫–æ—Ä—É
    scored_candidates.sort(key=lambda x: x[1], reverse=True)
    
    return scored_candidates


def diversify_results(
    scored_candidates: List[Tuple[int, float, str]],
    max_same_theme: int = 4
) -> List[Tuple[int, float, str]]:
    """
    –î–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: –Ω–µ –±–æ–ª–µ–µ N –ø–æ–¥—Ä—è–¥ –æ–¥–Ω–æ–π —Ç–µ–º—ã
    (–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ç–∏–ø—ã —É–¥–∞–ª–µ–Ω–∞ - –∫–∞–Ω–∞–ª—ã –º–æ–≥—É—Ç –∏–¥—Ç–∏ –¥—Ä—É–≥ –∑–∞ –¥—Ä—É–≥–æ–º)
    """
    diversified = []
    theme_counter = Counter()
    last_theme = None
    
    for project_id, score, reason in scored_candidates:
        if project_id not in project_data_cache:
            continue
        
        project_info = project_data_cache[project_id]
        project_theme = project_info.get('theme', '').lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å–ª–∏—à–∫–æ–º –ª–∏ –º–Ω–æ–≥–æ –ø–æ–¥—Ä—è–¥ –æ–¥–Ω–æ–π —Ç–µ–º—ã
        if project_theme == last_theme:
            theme_counter[project_theme] += 1
            if theme_counter[project_theme] > max_same_theme:
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º
        else:
            theme_counter.clear()
            theme_counter[project_theme] = 1
            last_theme = project_theme
        
        diversified.append((project_id, score, reason))
    
    return diversified


def get_recommendations(
    user_id: int,
    conn: sqlite3.Connection,
    content_type: Optional[str] = None,
    limit: int = 100
) -> List[Dict]:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –ø–æ–ª—É—á–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    """
    # 1. –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    user_profile = get_user_profile(user_id, conn)
    
    # 2. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    candidates = generate_candidates(user_profile, user_id, conn, content_type)
    
    if not candidates:
        # Fallback: –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç—ã
        return get_fallback_recommendations(conn, content_type, limit)
    
    # 3. –†–µ—Ä–∞–Ω–∫–∏–Ω–≥
    scored_candidates = rerank_candidates(candidates, user_profile, user_id, conn)
    
    # 4. –î–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
    diversified = diversify_results(scored_candidates)
    
    # 5. –ë–µ—Ä–µ–º —Ç–æ–ø-N
    top_candidates = diversified[:limit]
    
    # 6. –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    results = []
    for project_id, score, reason in top_candidates:
        if project_id in project_data_cache:
            project = dict(project_data_cache[project_id])
            project['recommendation_score'] = score
            project['recommendation_reason'] = reason
            results.append(project)
    
    return results


def get_fallback_recommendations(
    conn: sqlite3.Connection,
    content_type: Optional[str] = None,
    limit: int = 100
) -> List[Dict]:
    """
    Fallback —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —Ö–æ–ª–æ–¥–Ω–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞
    """
    cursor = conn.cursor()
    
    query = "SELECT * FROM projects WHERE 1=1"
    params = []
    
    if content_type and content_type != 'all':
        type_map = {'channels': 'channel', 'bots': 'bot', 'apps': 'mini_app'}
        target_type = type_map.get(content_type, content_type)
        query += " AND type = ?"
        params.append(target_type)
    
    query += " ORDER BY subscribers DESC, likes DESC LIMIT ?"
    params.append(limit)
    
    cursor.execute(query, params)
    rows = cursor.fetchall()
    
    results = []
    for row in rows:
        project = dict(row)
        project['recommendation_score'] = 0.0
        project['recommendation_reason'] = "–ü–æ–ø—É–ª—è—Ä–Ω–æ–µ"
        results.append(project)
    
    return results


def invalidate_user_cache(user_id: int):
    """–ò–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∫—ç—à –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    with _user_profile_cache_lock:
        if user_id in _user_profile_cache:
            del _user_profile_cache[user_id]


def get_cache_stats() -> Dict:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫—ç—à–∞ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    """
    with _user_profile_cache_lock:
        current_time = time.time()
        
        # –ü–æ–¥—Å—á–µ—Ç –∏—Å—Ç–µ–∫—à–∏—Ö –∑–∞–ø–∏—Å–µ–π
        expired_count = sum(
            1 for _, (_, timestamp) in _user_profile_cache.items()
            if current_time - timestamp > _USER_PROFILE_TTL
        )
        
        return {
            "total_cached_users": len(_user_profile_cache),
            "max_size": _USER_PROFILE_CACHE_MAX_SIZE,
            "usage_percent": round(len(_user_profile_cache) / _USER_PROFILE_CACHE_MAX_SIZE * 100, 2),
            "expired_entries": expired_count,
            "ttl_seconds": _USER_PROFILE_TTL,
            "ttl_hours": _USER_PROFILE_TTL / 3600
        }


def clear_all_cache():
    """
    –û—á–∏—â–∞–µ—Ç –≤–µ—Å—å –∫—ç—à –ø—Ä–æ—Ñ–∏–ª–µ–π (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –∏–ª–∏ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è)
    """
    with _user_profile_cache_lock:
        cleared_count = len(_user_profile_cache)
        _user_profile_cache.clear()
        return {"cleared_profiles": cleared_count}